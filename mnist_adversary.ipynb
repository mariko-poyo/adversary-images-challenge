{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate adversary image \n",
    "This code is trying to generate adversary images based on MNIST classifier provided in Tensorflow Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Tutorial  #1 (linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " load the dataset as written in tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#load mnist dataset\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define placeholders\n",
    "x_data = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_label = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression model\n",
    "def linear_model(epochs, batch_size):\n",
    "    #follow TensorFlow turtorial\n",
    "    #linear regression model\n",
    "    \n",
    "    #retrieve imgs\n",
    "    with open('./mnist_extract_imgs.p','rb') as f:\n",
    "        extracted_two_imgs,extracted_six_img = pickle.load(f)\n",
    "    \n",
    "    #declare variables\n",
    "    W = tf.Variable(tf.zeros([784,10]))\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "    \n",
    "     #setup loss function, gradient step, prediction, accuravy etc. \n",
    "    pred = tf.matmul(x_data,W) + b\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_label, logits=pred))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(y_label,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    #define labels of digit two img\n",
    "    two_label = [2]\n",
    "    label_onehot_two = np.eye(10)[two_label]\n",
    "    six_label = [6]\n",
    "    label_onehot_six = np.eye(10)[six_label]\n",
    "    epsilon = 0.25\n",
    "    \n",
    "    #define gradient to generate adversary img\n",
    "    grad = tf.gradients(cross_entropy,x_data)\n",
    "    \n",
    "    #np array to store generated imgs\n",
    "    generated_imgs = np.zeros((100,784))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #initialize variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        #train the model\n",
    "        for _ in range(epochs):\n",
    "            batch = mnist_data.train.next_batch(batch_size)\n",
    "            train_step.run(feed_dict={x_data: batch[0], y_label: batch[1]})\n",
    "\n",
    "        #evaluate the model by accuracy\n",
    "        print(\"Accuracy is:\", accuracy.eval(feed_dict={x_data: mnist_data.test.images, y_label: mnist_data.test.labels}))\n",
    "        \n",
    "        #generate adversarey image\n",
    "        #get the gradient of image six\n",
    "        grad_six = sess.run(grad,feed_dict={x_data:np.reshape(extracted_six_img,(1,784)), y_label:label_onehot_six})\n",
    "        \n",
    "        noise = epsilon * np.sign(grad_six)\n",
    "        for i in range(100):\n",
    "            grad_two = sess.run(grad,feed_dict={x_data:np.reshape(extracted_two_imgs[i],(1,784)), y_label:label_onehot_two})\n",
    "            noise_two = epsilon * np.sign(grad_two)\n",
    "            \n",
    "            generated_imgs[i] = noise_two + extracted_two_imgs[i] #- noise_two\n",
    "            pred_w = sess.run(pred,feed_dict={x_data:np.reshape(generated_imgs[i],(1,784))})\n",
    "            pred_w_index = np.argmax(pred_w)\n",
    "            print ('prediction: %d' %pred_w_index)\n",
    "        \n",
    "        return generated_imgs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.9192\n",
      "prediction: 6\n",
      "prediction: 5\n",
      "prediction: 3\n",
      "prediction: 1\n",
      "prediction: 6\n",
      "prediction: 0\n",
      "prediction: 7\n",
      "prediction: 8\n",
      "prediction: 0\n",
      "prediction: 9\n",
      "prediction: 3\n",
      "prediction: 5\n",
      "prediction: 8\n",
      "prediction: 3\n",
      "prediction: 3\n",
      "prediction: 6\n",
      "prediction: 3\n",
      "prediction: 8\n",
      "prediction: 3\n",
      "prediction: 3\n",
      "prediction: 6\n",
      "prediction: 7\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 6\n",
      "prediction: 8\n",
      "prediction: 1\n",
      "prediction: 6\n",
      "prediction: 5\n",
      "prediction: 6\n",
      "prediction: 5\n",
      "prediction: 7\n",
      "prediction: 1\n",
      "prediction: 3\n",
      "prediction: 6\n",
      "prediction: 1\n",
      "prediction: 7\n",
      "prediction: 1\n",
      "prediction: 3\n",
      "prediction: 7\n",
      "prediction: 0\n",
      "prediction: 6\n",
      "prediction: 0\n",
      "prediction: 8\n",
      "prediction: 7\n",
      "prediction: 5\n",
      "prediction: 3\n",
      "prediction: 8\n",
      "prediction: 1\n",
      "prediction: 7\n",
      "prediction: 7\n",
      "prediction: 1\n",
      "prediction: 8\n",
      "prediction: 3\n",
      "prediction: 1\n",
      "prediction: 6\n",
      "prediction: 6\n",
      "prediction: 1\n",
      "prediction: 4\n",
      "prediction: 8\n",
      "prediction: 0\n",
      "prediction: 8\n",
      "prediction: 8\n",
      "prediction: 4\n",
      "prediction: 8\n",
      "prediction: 1\n",
      "prediction: 6\n",
      "prediction: 6\n",
      "prediction: 6\n",
      "prediction: 1\n",
      "prediction: 3\n",
      "prediction: 6\n",
      "prediction: 1\n",
      "prediction: 8\n",
      "prediction: 8\n",
      "prediction: 8\n",
      "prediction: 3\n",
      "prediction: 8\n",
      "prediction: 8\n",
      "prediction: 0\n",
      "prediction: 7\n",
      "prediction: 3\n",
      "prediction: 3\n",
      "prediction: 3\n",
      "prediction: 8\n",
      "prediction: 8\n",
      "prediction: 3\n",
      "prediction: 3\n",
      "prediction: 8\n",
      "prediction: 8\n",
      "prediction: 6\n",
      "prediction: 3\n",
      "prediction: 6\n",
      "prediction: 3\n",
      "prediction: 8\n",
      "prediction: 8\n",
      "prediction: 1\n",
      "prediction: 8\n",
      "prediction: 3\n",
      "prediction: 6\n"
     ]
    }
   ],
   "source": [
    "#run the model\n",
    "imgs = linear_model(1000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcb3bc9de48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFOEHgiL8QFCEHwiK8ANBEX4gKMIPBPX/cJIWZYPGspgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb3bcd4518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize generated img\n",
    "plt.imshow(np.reshape(imgs[0],(28,28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Tutorial #2 (ConvNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshapre input data\n",
    "x_image = tf.reshape(x_data, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "declare saver to save all parameter values after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for declare variables\n",
    "def weight_variable(shape,name_):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial,name=name_)\n",
    "\n",
    "def bias_variable(shape,name_):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial,name=name_)\n",
    "\n",
    "#functions to define conv layer and pooling layes\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n",
      "step 100, training accuracy 0.82\n",
      "step 200, training accuracy 0.94\n",
      "step 300, training accuracy 0.98\n",
      "step 400, training accuracy 0.98\n",
      "step 500, training accuracy 0.96\n",
      "step 600, training accuracy 0.9\n",
      "step 700, training accuracy 0.96\n",
      "step 800, training accuracy 0.92\n",
      "step 900, training accuracy 1\n",
      "test accuracy 0.9592\n",
      "weight saved to ./MNIST_weight/model_weight.ckpt\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#convnet model\n",
    "\n",
    "#sess = tf.InteractiveSession()\n",
    "\n",
    "#declare parameter values\n",
    "W_conv1 = weight_variable([5, 5, 1, 32],\"W_conv1\")\n",
    "b_conv1 = bias_variable([32],\"b_conv1\")\n",
    "W_conv2 = weight_variable([5, 5, 32, 64],\"W_conv2\")\n",
    "b_conv2 = bias_variable([64],\"b_conv2\")\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024],\"W_fc1\")\n",
    "b_fc1 = bias_variable([1024],\"b_fc1\")\n",
    "W_fc2 = weight_variable([1024, 10],\"W_fc2\")\n",
    "b_fc2 = bias_variable([10],\"b_fc2\")\n",
    "\n",
    "#declare saver to save all parameter values and retrieve it later\n",
    "#saver = tf.train.Saver([W_conv1,b_conv1,W_conv2,b_conv2,W_fc1,b_fc1,W_fc2,b_fc2])\n",
    "\n",
    "#first layer\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#second conv layer\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#flatten->fc layer->dropout\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#last layer\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "#define loss func, gradient step, prediction\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_label, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy,var_list=[W_conv1, b_conv1,W_conv2,b_conv2,W_fc1,b_fc1,W_fc2,b_fc2])\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#define flags etc. to extract digit 2 images\n",
    "isDigitTwo = tf.equal(tf.argmax(y_label,1), 2)\n",
    "isCorrectTwo = tf.cast(tf.cast(correct_prediction,tf.float32) * tf.cast(isDigitTwo, tf.float32),tf.bool)\n",
    "isCorrectTwo_index = tf.where(isCorrectTwo)\n",
    "\n",
    "#also extract image of six\n",
    "isDigitSix = tf.equal(tf.argmax(y_label,1), 6)\n",
    "isCorrectSix = tf.cast(tf.cast(correct_prediction,tf.float32) * tf.cast(isDigitSix, tf.float32),tf.bool)\n",
    "isCorrectSix_index = tf.where(isCorrectSix)\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables()) #[W_conv1,b_conv1,W_conv2,b_conv2,W_fc1,b_fc1,W_fc2,b_fc2]\n",
    "\n",
    "#declare list to store extracted images and counter\n",
    "extracted_two_imgs = np.zeros((100,784))\n",
    "\n",
    "#train, evaluate\n",
    "with tf.Session() as sess:\n",
    "    #initialize parameters\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(1000): #20000\n",
    "        batch = mnist_data.train.next_batch(50)\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x_data: batch[0], y_label: batch[1], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x_data: batch[0], y_label: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "      x_data: mnist_data.test.images, y_label: mnist_data.test.labels, keep_prob: 1.0}))\n",
    "\n",
    "    #save the current parameter values\n",
    "    save_path = saver.save(sess,\"./MNIST_weight/model_weight.ckpt\")\n",
    "    print('weight saved to %s' %save_path)\n",
    "\n",
    "    #extract digit two\n",
    "    pred_two = sess.run(isCorrectTwo_index, feed_dict={x_data:mnist_data.test.images,y_label: mnist_data.test.labels, keep_prob:1.0})\n",
    "    index_two = [item for sublist in pred_two.tolist() for item in sublist]\n",
    "    for j in range(100):\n",
    "        extracted_two_imgs[j] = mnist_data.test.images[index_two[j]]\n",
    "    print(j)\n",
    "    \n",
    "    #extract digit six\n",
    "    pred_six = sess.run(isCorrectSix_index, feed_dict={x_data:mnist_data.test.images,y_label: mnist_data.test.labels, keep_prob:1.0})\n",
    "    index_six = [item for sublist in pred_six.tolist() for item in sublist]\n",
    "    extracted_six_img = mnist_data.test.images[index_six[0]]\n",
    "    \n",
    "    #pickle extracted imgs\n",
    "    with open('./mnist_extract_imgs.p','wb') as f:\n",
    "        pickle.dump([extracted_two_imgs,extracted_six_img],f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try to generate adversary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to generate adversary images by adding some noise to extracted image of digit 2. \n",
    "On writing this part, this link was really useful. [PASTE LINK LATER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, try to visualize extracted imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fcb3a465f98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb3bcea4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize one of the samples in extracted_two_imgs\n",
    "data = extracted_two_imgs[2]\n",
    "plt.imshow(np.reshape(data,(28,28)),cmap='gray')\n",
    "plt.title(\"extracted digit 2 image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re-define parameters as untrainable and also define noise images as variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate new images by using the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./MNIST_weight/model_weight.ckpt\n",
      "model is restored\n",
      "prediction is: 2\n",
      "prediction is: 2\n",
      "prediction is: 3\n",
      "prediction is: 4\n",
      "prediction is: 2\n",
      "prediction is: 3\n",
      "prediction is: 7\n",
      "prediction is: 2\n",
      "prediction is: 2\n",
      "prediction is: 8\n",
      "prediction is: 2\n",
      "prediction is: 9\n",
      "prediction is: 3\n",
      "prediction is: 2\n",
      "prediction is: 3\n",
      "prediction is: 3\n",
      "prediction is: 2\n",
      "prediction is: 0\n",
      "prediction is: 8\n",
      "prediction is: 3\n",
      "prediction is: 2\n",
      "prediction is: 2\n",
      "prediction is: 3\n",
      "prediction is: 1\n",
      "prediction is: 3\n",
      "prediction is: 2\n",
      "prediction is: 2\n",
      "prediction is: 1\n",
      "prediction is: 2\n",
      "prediction is: 3\n",
      "prediction is: 2\n",
      "prediction is: 2\n",
      "prediction is: 7\n",
      "prediction is: 1\n",
      "prediction is: 6\n",
      "prediction is: 1\n",
      "prediction is: 1\n",
      "prediction is: 2\n",
      "prediction is: 2\n",
      "prediction is: 0\n",
      "prediction is: 2\n",
      "prediction is: 0\n",
      "prediction is: 7\n",
      "prediction is: 2\n",
      "prediction is: 3\n",
      "prediction is: 2\n",
      "prediction is: 1\n",
      "prediction is: 1\n",
      "prediction is: 7\n",
      "prediction is: 2\n",
      "prediction is: 8\n",
      "prediction is: 2\n",
      "prediction is: 1\n",
      "prediction is: 2\n",
      "prediction is: 4\n",
      "prediction is: 1\n",
      "prediction is: 2\n",
      "prediction is: 8\n",
      "prediction is: 2\n",
      "prediction is: 7\n",
      "prediction is: 2\n",
      "prediction is: 2\n",
      "prediction is: 8\n",
      "prediction is: 6\n",
      "prediction is: 8\n",
      "prediction is: 2\n",
      "prediction is: 1\n",
      "prediction is: 2\n",
      "prediction is: 6\n",
      "prediction is: 1\n",
      "prediction is: 2\n",
      "prediction is: 2\n",
      "prediction is: 8\n",
      "prediction is: 2\n",
      "prediction is: 8\n",
      "prediction is: 0\n",
      "prediction is: 7\n",
      "prediction is: 3\n",
      "prediction is: 2\n",
      "prediction is: 2\n",
      "prediction is: 1\n",
      "prediction is: 8\n",
      "prediction is: 8\n",
      "prediction is: 4\n",
      "prediction is: 8\n",
      "prediction is: 2\n",
      "prediction is: 4\n",
      "prediction is: 2\n",
      "prediction is: 2\n",
      "prediction is: 2\n",
      "prediction is: 8\n",
      "prediction is: 2\n",
      "prediction is: 1\n",
      "prediction is: 2\n",
      "prediction is: 2\n",
      "prediction is: 6\n",
      "prediction is: 2\n",
      "prediction is: 8\n",
      "prediction is: 8\n",
      "prediction is: 2\n"
     ]
    }
   ],
   "source": [
    "#generate new image \n",
    "#retrieve variables \n",
    "with open('./mnist_extract_imgs.p','rb') as f:\n",
    "    extracted_two_imgs,extracted_six_img = pickle.load(f)\n",
    "\n",
    "#define correct class and make it one-hot code\n",
    "correct_class_two = [2]\n",
    "correct_onehot_two = np.eye(10)[correct_class_two]\n",
    "correct_class_six = [6]\n",
    "correct_onehot_six = np.eye(10)[correct_class_six]\n",
    "\n",
    "#re-define loss function etc.\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_label, logits=y_conv))\n",
    "gradient = tf.gradients(loss,x_data)\n",
    "epsilon = 0.07 #same as panda one\n",
    "\n",
    "#np array to store generated img\n",
    "gen_imgs = np.zeros((100,784))#extracted_two_imgs\n",
    "\n",
    "### generate\n",
    "with tf.Session() as sess:\n",
    "     #initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #restore parameter valuers\n",
    "    saver.restore(sess,\"./MNIST_weight/model_weight.ckpt\")\n",
    "    print('model is restored')\n",
    "    \n",
    "   \n",
    "    #for each image in extracted two, get gradient\n",
    "    for i in range(100):\n",
    "        \n",
    "        #TODO: rewrite this part\n",
    "        #the formula for added noise is:\n",
    "        # n = epcilon * sign(gradient of loss respect to x)\n",
    "        grad_img = sess.run(gradient, feed_dict={x_data:np.reshape(extracted_two_imgs[i],(1,784)), y_label:correct_onehot_two,keep_prob:1.0})\n",
    "        noise =  epsilon * np.sign(grad_img) \n",
    "        gen_imgs[i] = noise + extracted_two_imgs[i]\n",
    "\n",
    "        #printout prediction\n",
    "        pred_wrong = sess.run(y_conv, feed_dict={x_data:np.reshape(gen_imgs[i],(1,784)),keep_prob:1.0})\n",
    "        pred_id = np.argmax(pred_wrong)\n",
    "        print ('prediction is: %d' %pred_id)\n",
    "    \n",
    "    n = gen_imgs - extracted_two_imgs\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize noise images added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcb373a7208>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQFKEH0iK8ANJEX4gqf8BRWLBZQrYmmcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb39f902e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(n[0],(28,28)),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize generated img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcb3737b6a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb373b3518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(gen_imgs[0],(28,28)),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
